{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是使用 **PyTorch** 實現的 **SimpleRNN** 文本分類模型的完整程式，包括訓練、驗證和推論的流程。這個範例同樣使用 **IMDB 電影評論數據集** 進行情感分析（二元分類），並且包含詳細說明。\n",
    "\n",
    "### 完整的 SimpleRNN 文本分類範例（PyTorch）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.68583909923933\n",
      "Epoch 2, Loss: 0.6601734283019085\n",
      "Epoch 3, Loss: 0.6247793420845148\n",
      "Epoch 4, Loss: 0.5566335820725986\n",
      "Epoch 5, Loss: 0.5693632276082525\n",
      "Epoch 6, Loss: 0.5057790875434875\n",
      "Epoch 7, Loss: 0.5011934251809607\n",
      "Epoch 8, Loss: 0.4683507458896053\n",
      "Epoch 9, Loss: 0.4663297343923121\n",
      "Epoch 10, Loss: 0.42849518419528493\n",
      "Epoch 11, Loss: 0.41026523329165515\n",
      "Epoch 12, Loss: 0.41988153101838366\n",
      "Epoch 13, Loss: 0.37601008638739586\n",
      "Epoch 14, Loss: 0.36459423966553745\n",
      "Epoch 15, Loss: 0.4395275391942384\n",
      "Epoch 16, Loss: 0.37591155572813384\n",
      "Epoch 17, Loss: 0.4011821088438131\n",
      "Epoch 18, Loss: 0.36171723598120165\n",
      "Epoch 19, Loss: 0.32242497064325276\n",
      "Epoch 20, Loss: 0.31017847343975186\n",
      "Epoch 21, Loss: 0.3647009850460656\n",
      "Epoch 22, Loss: 0.3116025105879015\n",
      "Epoch 23, Loss: 0.28177873030000805\n",
      "Epoch 24, Loss: 0.29965338483452797\n",
      "Epoch 25, Loss: 0.3144880676908152\n",
      "Epoch 26, Loss: 0.2798818365803787\n",
      "Epoch 27, Loss: 0.26136297185202034\n",
      "Epoch 28, Loss: 0.28430439052837236\n",
      "Epoch 29, Loss: 0.29281128137087337\n",
      "Epoch 30, Loss: 0.25997024812564556\n",
      "Test Loss: 0.6344257603798594, Accuracy: 76.42%\n",
      "評論：'This movie was absolutely fantastic, I loved every part of it.'，預測情感：負面，概率：0.15\n"
     ]
    }
   ],
   "source": [
    "# 匯入必要的模組\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# 1. 資料準備\n",
    "# ---------------------------------------------------\n",
    "# 使用 Keras 提供的 IMDB 資料集，這裡只使用 10,000 個最常見的單詞\n",
    "max_features = 10000  # 最大詞彙數\n",
    "max_len = 500         # 每篇評論固定長度\n",
    "batch_size = 128      # 訓練的批次大小\n",
    "\n",
    "# 載入 IMDB 數據集，並將其分為訓練和測試集\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 將評論填充到固定長度（500 個詞）\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "# 轉換為 PyTorch tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.long)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 創建 DataLoader，方便訓練和驗證數據的批量處理\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "test_data = TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "# 2. 定義 SimpleRNN 模型\n",
    "# ---------------------------------------------------\n",
    "class SimpleRNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SimpleRNNModel, self).__init__()\n",
    "        # 嵌入層：將詞索引轉換為嵌入向量\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # SimpleRNN層\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # 最後的全連接層，將隱藏狀態映射到一個輸出\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # text shape: (batch_size, max_len)\n",
    "        embedded = self.embedding(text)  # (batch_size, max_len, embedding_dim)\n",
    "        output, hidden = self.rnn(embedded)  # hidden shape: (batch_size, hidden_dim)\n",
    "        return self.fc(hidden.squeeze(0))  # 將隱藏層輸出到全連接層，並返回結果\n",
    "\n",
    "# 定義模型參數\n",
    "vocab_size = max_features\n",
    "embedding_dim = 32\n",
    "hidden_dim = 32\n",
    "output_dim = 1  # 二元分類\n",
    "\n",
    "# 創建模型實例\n",
    "model = SimpleRNNModel(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.BCEWithLogitsLoss()  # 使用二元交叉熵損失\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 3. 模型訓練\n",
    "# ---------------------------------------------------\n",
    "# 定義訓練函數\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()  # 訓練模式\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()  # 梯度歸零\n",
    "            predictions = model(inputs).squeeze(1)  # 預測結果\n",
    "            loss = criterion(predictions, labels)  # 計算損失\n",
    "            loss.backward()  # 反向傳播\n",
    "            optimizer.step()  # 更新參數\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# 訓練模型\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# 4. 模型驗證\n",
    "# ---------------------------------------------------\n",
    "# 定義驗證函數\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()  # 評估模式\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # 關閉梯度計算\n",
    "        for inputs, labels in test_loader:\n",
    "            predictions = model(inputs).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            total_loss += loss.item()\n",
    "            acc = ((torch.sigmoid(predictions) >= 0.5) == labels).sum().item()  # 準確率\n",
    "            total_acc += acc\n",
    "    print(f\"Test Loss: {total_loss / len(test_loader)}, Accuracy: {total_acc / len(test_loader.dataset) * 100:.2f}%\")\n",
    "\n",
    "# 驗證模型\n",
    "evaluate_model(model, test_loader, criterion)\n",
    "\n",
    "# 5. 部屬推論\n",
    "# ---------------------------------------------------\n",
    "# 使用訓練好的模型進行推論\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()  # 設置模型為評估模式\n",
    "    tokenized = [1, 14, 22, 32, 65, 193, 17, 114, 325, 4]  # 假設這是處理過的 tokenized 序列\n",
    "    tokenized = torch.tensor(sequence.pad_sequences([tokenized], maxlen=max_len), dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(tokenized).squeeze(1)\n",
    "        prob = torch.sigmoid(prediction).item()\n",
    "        return \"正面\" if prob >= 0.5 else \"負面\", prob\n",
    "\n",
    "# 使用模型進行情感分析推論\n",
    "sentence = \"This movie was absolutely fantastic, I loved every part of it.\"\n",
    "sentiment, probability = predict_sentiment(model, sentence)\n",
    "print(f\"評論：'{sentence}'，預測情感：{sentiment}，概率：{probability:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 程式碼詳解：\n",
    "\n",
    "1. **資料準備**：\n",
    "   - 使用 Keras 提供的 **IMDB 電影評論數據集**，每篇評論都被轉換為一個詞彙索引序列。\n",
    "   - 每篇評論都被填充或截斷到固定長度（500個詞），並轉換為 PyTorch tensors。\n",
    "   - 創建 **DataLoader** 來幫助批量處理訓練和測試數據。\n",
    "\n",
    "2. **SimpleRNN 模型**：\n",
    "   - **Embedding 層**：將詞彙索引轉換為 32 維的嵌入向量。\n",
    "   - **SimpleRNN 層**：32 個隱藏單元，學習序列中的模式。`batch_first=True` 使輸入的批次維度排在最前面。\n",
    "   - **全連接層**：將最後的隱藏狀態輸出映射到一個二分類輸出，預測結果。\n",
    "\n",
    "3. **模型訓練**：\n",
    "   - 定義訓練函數 `train_model()`，每個訓練 epoch 會執行前向傳播、反向傳播和參數更新。\n",
    "   - 使用 **Adam** 優化器和 **BCEWithLogitsLoss** 損失函數（適合二元分類）。\n",
    "\n",
    "4. **模型驗證**：\n",
    "   - 使用 `evaluate_model()` 函數在測試集上進行評估。該函數會計算測試集的損失和準確率。\n",
    "\n",
    "5. **部屬推論**：\n",
    "   - 定義推論函數 `predict_sentiment()`，該函數接收處理過的句子，並使用訓練好的模型預測其情感，返回「正面」或「負面」的預測結果，以及對應的概率分數。\n",
    "\n",
    "### 結論：\n",
    "這個範例展示了使用 PyTorch 和 **SimpleRNN** 進行文本分類的完整流程，包括模型訓練、驗證和推論。該模型適用於情感分析等二元分類問題，並展示了如何在 PyTorch 中實現類似於 Keras 的工作流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完整的 SimpleRNN 文本分類範例（PyTorch）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入必要的模組\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# 1. 資料準備\n",
    "# ---------------------------------------------------\n",
    "# 我們使用 Keras 提供的 IMDB 資料集，其中每篇評論都被映射為一個詞彙索引序列\n",
    "# max_features 指定只使用前 10,000 個最常見的單詞\n",
    "# max_len 指定每篇評論固定為 500 個單詞\n",
    "max_features = 10000  # 最大詞彙數\n",
    "max_len = 500         # 每篇評論的長度限制\n",
    "\n",
    "# 載入 IMDB 電影評論數據集（已經分成訓練集和測試集）\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 將每篇評論填充或截斷至固定長度（500 個詞）\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "# 2. 建立 SimpleRNN 模型\n",
    "# ---------------------------------------------------\n",
    "# 模型包含嵌入層、SimpleRNN 層和輸出層，適合文本分類\n",
    "model = Sequential()\n",
    "\n",
    "# 嵌入層：將詞索引轉換為 32 維的向量表示\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32, input_length=max_len))\n",
    "\n",
    "# SimpleRNN 層：32 個單元，用於學習序列中的模式\n",
    "model.add(SimpleRNN(32))\n",
    "\n",
    "# 輸出層：1 個神經元，使用 sigmoid 激活函數進行二分類\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 編譯模型：使用 RMSprop 作為優化器，損失函數為 binary_crossentropy\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 顯示模型的架構\n",
    "model.summary()\n",
    "\n",
    "# 3. 訓練模型\n",
    "# ---------------------------------------------------\n",
    "# 使用訓練數據進行模型訓練，並在驗證集上進行評估\n",
    "# validation_split=0.2 表示將 20% 的訓練數據用作驗證集\n",
    "history = model.fit(\n",
    "    x_train, y_train,                    # 訓練數據和標籤\n",
    "    epochs=5,                            # 訓練週期數\n",
    "    batch_size=128,                      # 每次訓練批量大小\n",
    "    validation_split=0.2                 # 20% 用作驗證集\n",
    ")\n",
    "\n",
    "# 4. 驗證模型\n",
    "# ---------------------------------------------------\n",
    "# 使用測試數據評估模型的性能\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"測試集準確率: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# 5. 保存模型\n",
    "# ---------------------------------------------------\n",
    "# 將訓練好的模型保存至文件，以便後續推論使用\n",
    "model.save('simple_rnn_sentiment_model.h5')\n",
    "print(\"模型已保存至 'simple_rnn_sentiment_model.h5'\")\n",
    "\n",
    "# 6. 部屬推論\n",
    "# ---------------------------------------------------\n",
    "# 使用訓練好的模型進行推論（預測新評論的情感）\n",
    "# 我們將使用已保存的模型並對新評論進行分類\n",
    "# 重新加載模型\n",
    "model = load_model('simple_rnn_sentiment_model.h5')\n",
    "\n",
    "# 範例評論（假設評論是已經過處理的索引序列）\n",
    "sample_review = \"This movie was absolutely fantastic, I loved every part of it.\"\n",
    "sample_review_tokenized = [1, 14, 22, 32, 65, 193, 17, 114, 325, 4]  # 這裡需要一個有效的 tokenized 序列\n",
    "\n",
    "# 將評論填充到與訓練集相同的長度（500）\n",
    "sample_review_tokenized = sequence.pad_sequences([sample_review_tokenized], maxlen=max_len)\n",
    "\n",
    "# 預測這篇評論是正面（1）還是負面（0）\n",
    "prediction = model.predict(sample_review_tokenized)\n",
    "if prediction >= 0.5:\n",
    "    print(f\"評論情感預測：正面 ({prediction[0][0]:.2f})\")\n",
    "else:\n",
    "    print(f\"評論情感預測：負面 ({prediction[0][0]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 程式碼詳解：\n",
    "\n",
    "1. **資料準備**：\n",
    "   - 使用 Keras 提供的 **IMDB 電影評論數據集**，該數據集已被處理為詞彙索引序列，並且只保留了最常見的 10,000 個單詞。\n",
    "   - 每篇評論被截斷或填充至固定長度（500 個詞），以確保模型能處理固定長度的輸入。\n",
    "\n",
    "2. **建立 SimpleRNN 模型**：\n",
    "   - **Embedding 層**：將詞彙索引轉換為 32 維的詞向量，這使得模型能捕捉詞彙之間的語義關聯。\n",
    "   - **SimpleRNN 層**：RNN 層有 32 個神經元，用於學習序列中的模式和關聯。\n",
    "   - **Dense 層**：最終的輸出層是一個單神經元，使用 sigmoid 函數，輸出值為 0 到 1 之間，用於二元分類。\n",
    "\n",
    "3. **模型訓練與驗證**：\n",
    "   - **訓練**：將 80% 的數據用作訓練，20% 用於驗證。訓練 5 個週期，使用 batch size 為 128。\n",
    "   - **驗證**：在測試集上評估模型的準確率，並打印測試結果。\n",
    "\n",
    "4. **保存模型**：\n",
    "   - 模型訓練完後，使用 `model.save()` 函數保存模型，以便後續的推論使用。\n",
    "\n",
    "5. **部屬推論**：\n",
    "   - **加載已保存的模型**：用 `load_model()` 重新加載訓練好的模型。\n",
    "   - **進行推論**：對新評論進行推斷，並將其轉換為對應的索引序列。評論首先會被填充到固定長度，然後進行情感預測。如果預測值大於等於 0.5，則判斷為正面；否則為負面。\n",
    "\n",
    "### 結論：\n",
    "這個程式展示了如何使用 **SimpleRNN** 進行文本分類的完整流程，從訓練、驗證、保存模型到模型的推論部屬。這樣的模型可以應用於各種文本分類任務，如情感分析、垃圾郵件分類等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡我將使用一個經典的時間序列資料集 **Air Passenger Dataset** 來演示如何使用 **PyTorch** 和 **SimpleRNN** 進行時間序列預測。這個資料集記錄了1949年到1960年每月的國際航空旅客人數。\n",
    "\n",
    "### 完整的 SimpleRNN 時間序列預測範例（基於 Air Passenger Dataset）\n",
    "\n",
    "#### 步驟：\n",
    "1. **資料集下載與處理**\n",
    "2. **模型構建**\n",
    "3. **模型訓練**\n",
    "4. **模型驗證**\n",
    "5. **模型推論**\n",
    "\n",
    "### 完整程式碼 (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 匯入必要的模組\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 資料準備\n",
    "# ---------------------------------------------------\n",
    "# 讀取經典的 Air Passenger Dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "df = pd.read_csv(url, usecols=[1])\n",
    "\n",
    "# 檢查數據\n",
    "print(df.head())\n",
    "\n",
    "# 正規化數據到 [0, 1] 區間\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(df.values.reshape(-1, 1))\n",
    "\n",
    "# 設定序列長度\n",
    "seq_length = 12  # 使用前12個月來預測下一個月\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for i in range(len(data) - seq_length):\n",
    "    data_x.append(data[i:i + seq_length])  # 每次取12個數據作為輸入\n",
    "    data_y.append(data[i + seq_length])  # 取下一個月作為標籤\n",
    "\n",
    "# 轉換為 numpy array\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)\n",
    "\n",
    "# 分割訓練集和測試集 (80% 用於訓練, 20% 用於測試)\n",
    "train_size = int(len(data_x) * 0.8)\n",
    "x_train, x_test = data_x[:train_size], data_x[train_size:]\n",
    "y_train, y_test = data_y[:train_size], data_y[train_size:]\n",
    "\n",
    "# 轉換為 PyTorch tensors\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# 使用 DataLoader 加載數據\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=16)\n",
    "\n",
    "# 2. 定義 SimpleRNN 模型\n",
    "# ---------------------------------------------------\n",
    "class SimpleRNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, hidden = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # 取最後一個時間步的輸出\n",
    "        return out\n",
    "\n",
    "# 模型參數設定\n",
    "input_size = 1  # 單變量時間序列\n",
    "hidden_size = 64  # 隱藏層大小\n",
    "output_size = 1  # 預測單個點\n",
    "model = SimpleRNNModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# 定義損失函數和優化器\n",
    "criterion = nn.MSELoss()  # 均方誤差\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 3. 模型訓練\n",
    "# ---------------------------------------------------\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=50):\n",
    "    model.train()  # 設置模型為訓練模式\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()  # 梯度歸零\n",
    "            outputs = model(inputs)  # 模型預測\n",
    "            loss = criterion(outputs, labels)  # 計算損失\n",
    "            loss.backward()  # 反向傳播\n",
    "            optimizer.step()  # 更新參數\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# 訓練模型\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# 4. 模型驗證\n",
    "# ---------------------------------------------------\n",
    "# 定義驗證函數\n",
    "def evaluate_model(model, x_test, y_test, scaler):\n",
    "    model.eval()  # 設置模型為評估模式\n",
    "    with torch.no_grad():\n",
    "        predictions = model(x_test)  # 進行預測\n",
    "        loss = criterion(predictions, y_test)  # 計算驗證損失\n",
    "        print(f\"驗證損失 (MSE): {loss.item():.4f}\")\n",
    "        \n",
    "        # 將預測和實際數據逆縮放回原始範圍\n",
    "        predictions = scaler.inverse_transform(predictions.numpy())\n",
    "        y_test = scaler.inverse_transform(y_test.numpy())\n",
    "        \n",
    "        # 可視化預測結果\n",
    "        plt.plot(y_test, label=\"True Data\")\n",
    "        plt.plot(predictions, label=\"Predicted Data\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# 將測試集數據轉換為與模型兼容的形式\n",
    "x_test = x_test.unsqueeze(-1)\n",
    "\n",
    "# 進行驗證\n",
    "evaluate_model(model, x_test, y_test, scaler)\n",
    "\n",
    "# 5. 部屬推論\n",
    "# ---------------------------------------------------\n",
    "# 定義未來時間步的預測函數\n",
    "def predict_future(model, input_seq, future_steps, scaler):\n",
    "    model.eval()\n",
    "    predicted_sequence = []\n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0).unsqueeze(-1)  # 加入batch維度\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(future_steps):\n",
    "            prediction = model(input_seq)  # 進行預測\n",
    "            predicted_sequence.append(prediction.item())  # 保存預測結果\n",
    "            \n",
    "            # 將最新的預測加入輸入序列，並去掉最舊的一個點\n",
    "            input_seq = torch.cat((input_seq[:, 1:, :], prediction.unsqueeze(0).unsqueeze(-1)), dim=1)\n",
    "    \n",
    "    # 將結果逆縮放回原始範圍\n",
    "    predicted_sequence = scaler.inverse_transform(np.array(predicted_sequence).reshape(-1, 1))\n",
    "    return predicted_sequence\n",
    "\n",
    "# 使用部分測試數據來預測未來12個月的數據\n",
    "input_seq = x_test[-1].numpy()  # 使用測試集最後一段數據作為起始輸入\n",
    "future_steps = 12  # 預測未來12個點\n",
    "predicted_future = predict_future(model, input_seq, future_steps, scaler)\n",
    "\n",
    "print(\"未來 12 個月的預測值：\", predicted_future)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 程式碼詳解：\n",
    "\n",
    "1. **資料準備**：\n",
    "   - 使用 **Air Passenger Dataset**，這是一個經典的時間序列資料集，包含 1949 年到 1960 年的每月航空旅客數據。\n",
    "   - 使用 **MinMaxScaler** 將數據縮放到 [0, 1] 範圍，這樣可以讓模型的訓練過程更加穩定。\n",
    "   - 將數據切分為訓練集（80%）和測試集（20%），並構建 PyTorch 的 **DataLoader**，方便批量訓練。\n",
    "\n",
    "2. **定義 SimpleRNN 模型**：\n",
    "   - **SimpleRNN 層**：使用 PyTorch 的 `nn.RNN`，用來處理序列數據。這個層可以學習序列中的模式。\n",
    "   - **全連接層**：最終使用一個線性層將隱藏層的輸出轉換為預測值。\n",
    "\n",
    "3. **模型訓練**：\n",
    "   - 使用 **Adam** 優化器來優化模型參數，損失函數使用 **MSELoss**（均方誤差），因為這是一個回歸問題。\n",
    "   - 模型在每個 epoch 都會根據訓練數據更新參數，並計算損失。\n",
    "\n",
    "4. **模型驗證**：\n",
    "   - 使用部分數據來驗證模型的準確性，並將預測值與真實值可視化，觀察模型的預測效果。\n",
    "\n",
    "5. **部屬推論**：\n",
    "   - 定義了一個 `predict_future()` 函數，根據當前的輸入序列，預測未來的時間步。該函數允許模型根據前一步的預測作為下一步的輸入，進行多步預測。\n",
    "\n",
    "### 結論：\n",
    "這個程式展示了如何使用 **PyTorch**\n",
    "\n",
    " 和 **SimpleRNN** 模型進行時間序列預測，基於經典的 **Air Passenger Dataset**。整個流程包括數據處理、模型訓練、驗證以及多步推論。這個流程同樣適用於其他類型的時間序列預測問題，例如天氣預測、股票價格預測等。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch231_cuda121_python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
